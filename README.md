# Book Recommendation Engine

Перш ніж виконувати скрипти створіть середовище за допомогою pyenv та встановіть залежності 

```bash
pip install -r requirements.txt
```

Для коректного логування та трекінгу експериментів потрібно створити файл .env у корені проекту з такими змінними:

```
WANDB_PROJECT=ваш_проект
WANDB_LOG_MODEL=checkpoint
WANDB_WATCH=all
WANDB_API_KEY=ващ_ключ
```

## 1. Запуск демонстраційного застосунку

Для швидкого ознайомлення з роботою рекомендаційної системи можна запустити наступний скрипт:

```bash
docker build -t my-streamlit-app .

docker run -p 8501:8501 my-streamlit-app
```

Далі можна відкрити URL в браузері для тестування за портом 8501

http://0.0.0.0:8501


---

Скрипти

```bash
# для train/test/val спліту
python scripts/split.py

# для валідації метрик
python scripts/eval.py

# для валідації тренування
python scripts/train.py

```

---

## 2. Метод пошуку найрелевантніших категорій

Я обрав bi-directional encoder архітектуру для зіставлення книги з потенційними категоріями.

* **Ідея:** водночас відтворювати векторні представлення і для книги, і для кожної категорії, а потім вимірювати косинусну близькість між ними.
* **Переваги:**

*  дає змогу краще захоплювати контекст із обох сторін тексту
  * підвищена стійкість до нюансів — модель навчається розуміти, як саме окремі частини опису книги співвідносяться з різними категорійними ознаками.


## 3. Визначення метрик якості

Щоб оцінити реальну користь рекомендацій, ми вимірюємо:

Precision@K корисна, коли нам важливо мінімізувати «сміття» у верхніх позиціях.

Recall@K важлива, коли потрібно «покрити» якомога більше релевантного за перші K.

mAP і mAP@K поєднують у собі обидва аспекти, штрафуючи як за пізнє знаходження релевантних, так і за наявність нерелевантних між ними.


## 4. Трекінг експериментів

Для прозорого та відтворюваного аналізу результатів я використовую **Weights & Biases**:


Найкраще тренування:
https://wandb.ai/urik-voevidka-ukrainian-catholic-university/sentence-transformers/runs/udz5qkc0

## 5. Потенційне покращення: зворотний зв’язок від користувача

Щоб ще більше підвищити релевантність рекомендацій, я запроваджую механізм **онлайн-коригування**:

* Користувач бачить запропоновану категорію і може її «лайкнути» або «дизлайкнути»
* Зібрані реакції надходять у реаль­ному часі й використовуються для донавчання (fine-tuning) моделі або для коригування вагів у ранжуванні


## 6. Результати 

## результати на Тест Сеті до тренування 
| Метрика                   | Значення |
| :------------------------ | :------: |
| **Precision\@1 (P\@1)**   |  0.0190  |
| **Precision\@5 (P\@5)**   |  0.0171  |
| **Precision\@10 (P\@10)** |  0.0132  |
| **Recall\@1 (R\@1)**      |  0.0103  |
| **Recall\@5 (R\@5)**      |  0.0472  |
| **Recall\@10 (R\@10)**    |  0.0730  |
| **Mean AP (mAP)**         |  0.0404  |
| **Mean AP\@15 (mAP\@15)** |  0.0290  |


## результати на Тест Сеті після тренування
| Метрика                   | Значення |
| :------------------------ | :------: |
| **Precision\@1 (P\@1)**   |  0.1755  |
| **Precision\@5 (P\@5)**   |  0.1085  |
| **Precision\@10 (P\@10)** |  0.0810  |
| **Recall\@1 (R\@1)**      |  0.0935  |
| **Recall\@5 (R\@5)**      |  0.2828  |
| **Recall\@10 (R\@10)**    |  0.4191  |
| **Mean AP (mAP)**         |  0.2332  |
| **Mean AP\@15 (mAP\@15)** |  0.2073  |


## 7. PCA
Для порівняння я спроектував ебмедінги натренованої і базової моделі на 2d графіку
Можна спостерігати що після тренування ембедінги стали більше розрідженими

![alt text](pca.png)

це результат ноутбуку notebooks/pca_comparison.ipynb

посилання на натреновану модель на hugging face: yuriivoievidka/microsoft_mpnet-base-librarian